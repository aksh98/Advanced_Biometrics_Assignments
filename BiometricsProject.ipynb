{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiometricsProject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/aksh98/Advanced_Biometrics_Assignments/blob/master/BiometricsProject.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "3jdvLJQmZb-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "900423ac-7518-4ae8-966f-aa9c0d89dc15"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.layers import Activation,Dropout,Bidirectional,Flatten,Dense,Conv2D,MaxPooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hxREJ9HHaI4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "596ad718-2878-4ea9-930f-80292db79cd9"
      },
      "cell_type": "code",
      "source": [
        "#Args - input_tensor=\n",
        "model = VGG16()\n",
        "\n",
        "print(model.summary())\n",
        "# plot_model(model, to_file='vgg.png')\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DhwPDu5hKSn5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## ================================================================\n",
        "## ========= INPUTS ===============================================\n",
        "\n",
        "def video_to_frames(input_loc, output_loc):\n",
        "    \"\"\"    Args:\n",
        "        input_loc: Input video file.\n",
        "        output_loc: Output directory to save the frames.\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    import time\n",
        "    import cv2\n",
        "    import os\n",
        "    try:\n",
        "        os.mkdir(output_loc)\n",
        "    except OSError:\n",
        "        pass\n",
        " \n",
        "    time_start = time.time()\n",
        "    \n",
        "    cap = cv2.VideoCapture(input_loc)\n",
        "    \n",
        "    video_length = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT)) - 1\n",
        "    print (\"Number of frames: \", video_length)\n",
        "    count = 0\n",
        "    print (\"Converting video..\\n\")\n",
        "    # Start converting the video\n",
        "    while cap.isOpened():\n",
        "        # Extract the frame\n",
        "        ret, frame = cap.read()\n",
        "        # Write the results back to output location.\n",
        "        cv2.imwrite(output_loc + \"/%#05d.jpg\" % (count+1), frame)\n",
        "        count = count + 1\n",
        "        # If there are no more frames left\n",
        "        if (count > (video_length-1)):\n",
        "            # Log the time again\n",
        "            time_end = time.time()\n",
        "            # Release the feed\n",
        "            cap.release()\n",
        "            # Print stats\n",
        "            print (\"Done extracting frames.\\n%d frames extracted\" % count)\n",
        "            print (\"It took %d seconds forconversion.\" % (time_end-time_start))\n",
        "            break\n",
        "\n",
        "## ================================================================\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KIAZ54k7Yjyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "203620cb-074f-409e-bba1-3f8236a77914"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpe9wkic6e/pubring.gpg' created\n",
            "gpg: /tmp/tmpe9wkic6e/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y6GN1lVsYmgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d56c53b9-6e1d-4bfe-be9b-4ebac98f6501"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\r\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wRd0gqHrYIDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb311460-7ade-44ae-892e-a9c8ac64b3c7"
      },
      "cell_type": "code",
      "source": [
        "%cd drive\n",
        "%cd Colab Notebooks"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content/drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sf1EwssvbwH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d3d90bd-a072-4362-db3a-9b33df4347a7"
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  drive\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hwOIcHgSbAt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c5289614-be58-4c6a-c9cd-574fa2ae7f9a"
      },
      "cell_type": "code",
      "source": [
        "# X_train, Y_train, X_valid, Y_valid = load_data()\n",
        "img_width, img_height = 224,224\n",
        "width_test,ht_test = 224,224\n",
        "train_data_dir = 'BiomProject/train'\n",
        "test_data_dir = 'BiomProject/test'\n",
        "\n",
        "train_samples = 2717\n",
        "test_samples = 153\n",
        "\n",
        "# train - 1537 (0-1536) original samples\n",
        "#         2717 (0-2716)total samples 250*250 - 1180\n",
        "\n",
        "# test - 0-86 = 87 swapped \n",
        "#        87-152 = original 158*215 97*150\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "original_len = 1537  \n",
        "swapped_len = 1180\n",
        "\n",
        "swapped_test = 87\n",
        "original_test = 66 \n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# For Theano\n",
        "# Switch RGB to BGR order \n",
        "# x = x[:, ::-1, :, :]\n",
        "# # Subtract ImageNet mean pixel \n",
        "# x[:, :, :, 0] -= 103.939\n",
        "# x[:, :, :, 1] -= 116.779\n",
        "# x[:, :, :, 2] -= 123.68\n",
        "\n",
        "top_model_weights_path = 'BiomProject/bottleneck_model.h5'\n",
        "weights_path = 'BiomProject/vgg16_weights.h5'\n",
        "\n",
        "# model_weights_path = 'fc_model.h5'\n",
        "\n",
        "def save_bottleneck_features():\n",
        "    model = VGG16(include_top=False, weights = 'imagenet')\n",
        "    \n",
        "# Data Augmentation ------------------------------------------\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        width_shift_range = 0.2,\n",
        "        height_shift_range = 0.2,\n",
        "        rescale = 1./255,\n",
        "        shear_range = 0.2,\n",
        "        zoom_range = 0.2,\n",
        "        horizontal_flip = True,\n",
        "        fill_mode = 'nearest')\n",
        "    print(\"augmentation done1\")\n",
        "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "#     print(\"train_Samples\",train_samples)\n",
        "    \n",
        "# Data Generator --------------------------------------------\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',shuffle=False)\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size = (width_test, ht_test),\n",
        "        batch_size = batch_size, \n",
        "        class_mode = None) # yield batches of data, no labels\n",
        "\n",
        "    train_samples = len(train_generator.filenames)  \n",
        "    test_samples = len(test_generator.filenames)\n",
        "    \n",
        "    print(\"train_Samples\",train_samples)\n",
        "    print(\"test_samples\",test_samples)\n",
        "    \n",
        "    print(\"data_generated2\")\n",
        "    predict_size_train = int(math.ceil(train_samples / batch_size))\n",
        "    predict_size_test = int(math.ceil(test_samples / batch_size))\n",
        "    # if predict_size_test not perfect - give hardcoded input\n",
        "    bottleneck_features_train = model.predict_generator(train_generator, predict_size_train)\n",
        "    print(\"predict_generator1\")\n",
        "    bottleneck_features_test = model.predict_generator(test_generator, predict_size_test)\n",
        "    print(\"predict_generator2\")\n",
        "#     np.save(open('bottleneck_features_train.npy','wb'),bottleneck_features_train)\n",
        "    np.save('bottleneck_features_train',bottleneck_features_train)\n",
        "    \n",
        "    np.save('bottleneck_features_test',bottleneck_features_test)\n",
        "    \n",
        "#     np.save(open('bottleneck_features_test.npy','wb'),bottleneck_features_test)\n",
        "    print(\"bottleneck_features_saved3\")\n",
        "    \n",
        "save_bottleneck_features()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "augmentation done1\n",
            "Found 2716 images belonging to 2 classes.\n",
            "Found 152 images belonging to 2 classes.\n",
            "train_Samples 2716\n",
            "test_samples 152\n",
            "data_generated2\n",
            "predict_generator1\n",
            "predict_generator2\n",
            "bottleneck_features_saved3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JO7M81yJYGDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2306
        },
        "outputId": "29074cdd-0a6b-4a50-dd0c-ded9ac2aa28f"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "original_len = 1536  \n",
        "swapped_len = 1180\n",
        "\n",
        "swapped_test = 86\n",
        "original_test = 66 \n",
        "\n",
        "def train_top_model():\n",
        "    \n",
        "#     train_data = np.load(open('bottleneck_features_train.npy','wb'))\n",
        "#     test_data = np.load(open('bottleneck_features_test.npy','wb'))\n",
        "    train_data = np.load('bottleneck_features_train.npy')\n",
        "    test_data = np.load('bottleneck_features_test.npy')\n",
        "    print(train_data.shape)\n",
        "    print(test_data.shape)\n",
        "    \n",
        "    \n",
        "    ####  CHANGE THISSSSS -------------------\n",
        "    \n",
        "    train_labels = np.array([0]*original_len + [1]*swapped_len).astype('float32')\n",
        "    test_labels = np.array([0]*original_test + [1]*swapped_test).astype('float32')\n",
        "    \n",
        "    ##### -----------------------------------\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(256,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "          optimizer='rmsprop',\n",
        "          metrics=['accuracy'])\n",
        "    \n",
        "    print(\"heylp\")\n",
        "    history = model.fit(train_data,train_labels,\n",
        "             epochs=epochs,batch_size = batch_size)\n",
        "    \n",
        "    model.save_weights(top_model_weights_path)\n",
        "    \n",
        "    (eval_loss,eval_accuracy) = model.evaluate(test_data,test_labels,batch_size=batch_size,verbose=1)\n",
        "    \n",
        "    plt.figure(1)  \n",
        "    \n",
        "     # summarize history for accuracy  \n",
        "    plt.subplot(211)  \n",
        "    plt.plot(history.history['acc'])  \n",
        "    plt.plot(history.history['val_acc'])  \n",
        "    plt.title('model accuracy')  \n",
        "    plt.ylabel('accuracy')  \n",
        "    plt.xlabel('epoch')  \n",
        "    plt.legend(['train', 'test'], loc='upper left')  \n",
        "\n",
        "     # summarize history for loss  \n",
        "\n",
        "    plt.subplot(212)  \n",
        "    plt.plot(history.history['loss'])  \n",
        "    plt.plot(history.history['val_loss'])  \n",
        "    plt.title('model loss')  \n",
        "    plt.ylabel('loss')  \n",
        "    plt.xlabel('epoch')  \n",
        "    plt.legend(['train', 'test'], loc='upper left')  \n",
        "    plt.show()\n",
        "    \n",
        "#     np.save('class_indices.npy',generator_top.class_indices)\n",
        "    \n",
        "    \n",
        "#     model.fit_generator(\n",
        "#         train_generator,\n",
        "#         steps_per_epoch= train_samples // batch_size,\n",
        "#         epochs=epochs,\n",
        "#         validation_data= test_generator,\n",
        "#         validation_steps= test_samples // batch_size)\n",
        "   \n",
        "\n",
        "train_top_model()\n",
        "# fine_tune()\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2716, 7, 7, 512)\n",
            "(152, 7, 7, 512)\n",
            "heylp\n",
            "Epoch 1/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.3656 - acc: 0.9554\n",
            "Epoch 2/50\n",
            "2716/2716 [==============================] - 3s 995us/step - loss: 0.1921 - acc: 0.9794\n",
            "Epoch 3/50\n",
            "2716/2716 [==============================] - 3s 986us/step - loss: 0.1216 - acc: 0.9871\n",
            "Epoch 4/50\n",
            "2716/2716 [==============================] - 3s 985us/step - loss: 0.0997 - acc: 0.9897\n",
            "Epoch 5/50\n",
            "2716/2716 [==============================] - 3s 991us/step - loss: 0.0742 - acc: 0.9923\n",
            "Epoch 6/50\n",
            "2224/2716 [=======================>......] - ETA: 0s - loss: 0.0568 - acc: 0.9951"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0526 - acc: 0.9952\n",
            "Epoch 7/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0436 - acc: 0.9959\n",
            "Epoch 8/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0332 - acc: 0.9974\n",
            "Epoch 9/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0271 - acc: 0.9974\n",
            "Epoch 10/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0425 - acc: 0.9956\n",
            "Epoch 11/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0326 - acc: 0.9963\n",
            "Epoch 12/50\n",
            " 784/2716 [=======>......................] - ETA: 1s - loss: 6.8058e-05 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0364 - acc: 0.9963\n",
            "Epoch 13/50\n",
            "2716/2716 [==============================] - 3s 993us/step - loss: 0.0102 - acc: 0.9985\n",
            "Epoch 14/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0237 - acc: 0.9967\n",
            "Epoch 15/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0392 - acc: 0.9952\n",
            "Epoch 16/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0194 - acc: 0.9982\n",
            "Epoch 17/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0238 - acc: 0.9967\n",
            "Epoch 18/50\n",
            " 384/2716 [===>..........................] - ETA: 2s - loss: 0.0598 - acc: 0.9948"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0202 - acc: 0.9982\n",
            "Epoch 19/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0213 - acc: 0.9974\n",
            "Epoch 20/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0244 - acc: 0.9982\n",
            "Epoch 21/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0301 - acc: 0.9978\n",
            "Epoch 22/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 6.0669e-04 - acc: 0.9993\n",
            "Epoch 23/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0024 - acc: 0.9993\n",
            "Epoch 24/50\n",
            " 304/2716 [==>...........................] - ETA: 2s - loss: 0.0312 - acc: 0.9967"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0038 - acc: 0.9996\n",
            "Epoch 25/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0098 - acc: 0.9993\n",
            "Epoch 26/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0140 - acc: 0.9989\n",
            "Epoch 27/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0081 - acc: 0.9993\n",
            "Epoch 28/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0179 - acc: 0.9985\n",
            "Epoch 29/50\n",
            "2716/2716 [==============================] - 3s 994us/step - loss: 1.0399e-04 - acc: 1.0000\n",
            "Epoch 30/50\n",
            " 560/2716 [=====>........................] - ETA: 2s - loss: 0.0100 - acc: 0.9964"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0080 - acc: 0.9989\n",
            "Epoch 31/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0127 - acc: 0.9989\n",
            "Epoch 32/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0059 - acc: 0.9996\n",
            "Epoch 33/50\n",
            "2716/2716 [==============================] - 3s 988us/step - loss: 0.0215 - acc: 0.9982\n",
            "Epoch 34/50\n",
            "2716/2716 [==============================] - 3s 993us/step - loss: 0.0036 - acc: 0.9993\n",
            "Epoch 35/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0077 - acc: 0.9993\n",
            "Epoch 36/50\n",
            " 608/2716 [=====>........................] - ETA: 2s - loss: 1.0765e-07 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0052 - acc: 0.9993\n",
            "Epoch 37/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 2.1108e-04 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "2716/2716 [==============================] - 3s 992us/step - loss: 0.0011 - acc: 0.9996\n",
            "Epoch 39/50\n",
            "2716/2716 [==============================] - 3s 986us/step - loss: 0.0060 - acc: 0.9996\n",
            "Epoch 40/50\n",
            "2716/2716 [==============================] - 3s 986us/step - loss: 0.0038 - acc: 0.9996\n",
            "Epoch 41/50\n",
            "2716/2716 [==============================] - 3s 981us/step - loss: 0.0126 - acc: 0.9985\n",
            "Epoch 42/50\n",
            " 624/2716 [=====>........................] - ETA: 2s - loss: 1.0917e-07 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2716/2716 [==============================] - 3s 992us/step - loss: 0.0081 - acc: 0.9993\n",
            "Epoch 43/50\n",
            "2716/2716 [==============================] - 3s 982us/step - loss: 0.0079 - acc: 0.9989\n",
            "Epoch 44/50\n",
            "2716/2716 [==============================] - 3s 1ms/step - loss: 0.0031 - acc: 0.9996\n",
            "Epoch 45/50\n",
            "2716/2716 [==============================] - 3s 985us/step - loss: 0.0059 - acc: 0.9996\n",
            "Epoch 46/50\n",
            "2716/2716 [==============================] - 3s 989us/step - loss: 0.0059 - acc: 0.9996\n",
            "Epoch 47/50\n",
            "2716/2716 [==============================] - 3s 977us/step - loss: 0.0040 - acc: 0.9993\n",
            "Epoch 48/50\n",
            " 768/2716 [=======>......................] - ETA: 1s - loss: 0.0139 - acc: 0.9987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2716/2716 [==============================] - 3s 997us/step - loss: 0.0165 - acc: 0.9974\n",
            "Epoch 49/50\n",
            "2716/2716 [==============================] - 3s 992us/step - loss: 0.0059 - acc: 0.9996\n",
            "Epoch 50/50\n",
            "2716/2716 [==============================] - 3s 984us/step - loss: 0.0033 - acc: 0.9996\n",
            "152/152 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-348bd081efd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mtrain_top_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;31m# fine_tune()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-348bd081efd5>\u001b[0m in \u001b[0;36mtrain_top_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAACnCAYAAAArIpSMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7b3a6c4d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3Jgt2fAJLL0l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " def fine_tune():\n",
        "    model = VGG16(weights='imagenet',include_top=False)\n",
        "    \n",
        "    top_model = Sequential()\n",
        "    top_model.add(Flatten(input_shape = model.output_shape[1:]))\n",
        "    top_model.add(Dense(256,activation='relu'))\n",
        "    top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(1,activation='sigmoid'))\n",
        "    \n",
        "    top_model.load_weights(top_model_weights_path)\n",
        "    \n",
        "    model.add(top_model)\n",
        "    \n",
        "    for layer in model.layers[:25]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                 optimizer=optimizers.SGD(lr=0.0001,momentum=0.9),\n",
        "                 metrics=['accuracy'])\n",
        "    \n",
        "    train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "          zoom_range=0.2,\n",
        "          shear_range=0.2,\n",
        "          horizontal_flip=True,\n",
        "          height_shift_range = 0.2,\n",
        "          width_shift_range = 0.2,\n",
        "          fill_mode='nearest')\n",
        "    \n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                      target_size = (img_height,img_width),\n",
        "                      batch_size = batch_size,class_mode='binary')\n",
        "    \n",
        "    test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
        "                      target_size = (ht_test,width_test),\n",
        "                      batch_size = batch_size,class_mode='binary')\n",
        "    \n",
        "    train_samples = len(train_generator.filenames)  \n",
        "    test_samples = len(test_generator.filenames)\n",
        "    \n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        samples_per_epoch=train_samples,\n",
        "        epochs=epochs,\n",
        "        validation_data=test_generator,\n",
        "        nb_val_samples=test_samples)\n",
        "     \n",
        "fine_tune()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}